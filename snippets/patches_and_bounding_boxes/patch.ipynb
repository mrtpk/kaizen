{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path_file):\n",
    "    with open(path_file) as file_ptr:\n",
    "        data = json.load(file_ptr)\n",
    "    return data\n",
    "def write_json(path_file, data):\n",
    "    with open(path_file, \"w\") as file_ptr:\n",
    "        json.dump(data, file_ptr, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePatcher():\n",
    "    '''\n",
    "    Assumes that the input images to the patcher will be of same size\n",
    "    '''\n",
    "    def __init__(self, patch_sz, overlap):\n",
    "        self.window_sz = patch_sz\n",
    "        self.overlap = overlap\n",
    "    \n",
    "    def calculate_padding_for_same_pad(self, input_sz, kernel_sz, stride):\n",
    "        '''\n",
    "        Calculate required padding such that kernel convolves on the\n",
    "        entire input\n",
    "        '''\n",
    "        output_sz = np.ceil(input_sz / stride)\n",
    "        total_pad = (output_sz - 1) * stride - input_sz + kernel_sz\n",
    "        \n",
    "        low_priority_pad = total_pad // 2\n",
    "        high_priority_pad = total_pad - low_priority_pad\n",
    "        return low_priority_pad, high_priority_pad\n",
    "    \n",
    "    def get_num_windows_along_axis(self, axis_len, window_len, overlap):\n",
    "        '''\n",
    "        Params:\n",
    "        ------\n",
    "        + axis_len - number of pixels along an axis of image\n",
    "        + window_len - number of pixels along an axis of window\n",
    "        + overlap - overlap between two windows in percentage\n",
    "        Returns:\n",
    "        -------\n",
    "        + number of windows along the axis\n",
    "        + stride - number of pixels for the jump\n",
    "        + number of pad with low priority (left pad along width, top pad along height)\n",
    "        + number of pad with high priority (right pad along width, bottom pad along height)\n",
    "        '''\n",
    "        stride = np.floor(window_len * (100 - overlap) * 0.01)\n",
    "        low_priority_pad, high_priority_pad = self.calculate_padding_for_same_pad(input_sz=axis_len, kernel_sz=window_len, stride=stride)\n",
    "        num_windows =int(((axis_len - window_len + low_priority_pad + high_priority_pad) // stride)) + 1    \n",
    "        return int(num_windows), int(stride), int(low_priority_pad), int(high_priority_pad)\n",
    "    \n",
    "    def is_inside_bbox(self, point, bbox):\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        point_x, point_y = point\n",
    "        return point_x >= xmin and point_x <= xmax and point_y >= ymin and point_y <= ymax\n",
    "    \n",
    "    def get_patch_annotations(self, patch_xmin, patch_xmax, patch_ymin, patch_ymax, annotations):\n",
    "        patch_bboxs = []\n",
    "        patch_box = (patch_xmin, patch_ymin, patch_xmax, patch_ymax)\n",
    "        for bbox in annotations:\n",
    "            xmin, ymin, xmax, ymax = bbox\n",
    "            xmin = xmin + self.left_pad\n",
    "            xmax = xmax + self.left_pad\n",
    "            ymin = ymin + self.top_pad\n",
    "            ymax = ymax + self.top_pad\n",
    "            \n",
    "            if self.is_inside_bbox(point=(xmin, ymin), bbox=patch_box) or \\\n",
    "               self.is_inside_bbox(point=(xmin, ymax), bbox=patch_box) or \\\n",
    "               self.is_inside_bbox(point=(xmax, ymin), bbox=patch_box) or \\\n",
    "               self.is_inside_bbox(point=(xmax, ymax), bbox=patch_box):\n",
    "                patch_bbox_xmin = max(xmin, patch_xmin) - patch_xmin\n",
    "                patch_bbox_ymin = max(ymin, patch_ymin) - patch_ymin\n",
    "                patch_bbox_xmax = min(xmax, patch_xmax) - patch_xmin\n",
    "                patch_bbox_ymax = min(ymax, patch_ymax) - patch_ymin\n",
    "                patch_bboxs.append([patch_bbox_xmin, patch_bbox_ymin, patch_bbox_xmax, patch_bbox_ymax])\n",
    "        return patch_bboxs\n",
    "\n",
    "    def generate_patches(self, path_img_file, path_json_file=None):\n",
    "        \"\"\"\n",
    "        Generate patches from image provided\n",
    "        \"\"\"\n",
    "        img = cv2.imread(path_img_file)\n",
    "        if path_json_file is not None:\n",
    "            annotations = read_json(path_json_file)\n",
    "\n",
    "        self.height, self.width, self.channels = img.shape\n",
    "        self.dtype = img.dtype\n",
    "        self.num_rows, self.row_stride, self.left_pad, self.right_pad = self.get_num_windows_along_axis(axis_len=self.height, window_len=self.window_sz,overlap=self.overlap)\n",
    "        self.num_cols, self.col_stride, self.top_pad, self.bottom_pad = self.get_num_windows_along_axis(axis_len=self.width, window_len=self.window_sz,overlap=self.overlap)\n",
    "        \n",
    "        self.padded_img_height = self.height+self.left_pad+self.right_pad\n",
    "        self.padded_img_width = self.width+self.top_pad+self.bottom_pad\n",
    "        padded_img = np.zeros(shape=(self.padded_img_height, self.padded_img_width, self.channels), dtype=self.dtype)\n",
    "        padded_img[self.left_pad:self.left_pad+self.height, self.right_pad:self.right_pad+self.width, :] = img\n",
    "        # cv2.imwrite(\"padded_img.png\", padded_img)\n",
    "\n",
    "        path_patch_dir = Path(\"dataset/patches/\")\n",
    "        path_patch_dir.mkdir(parents=True, exist_ok=True)\n",
    "        image_filename = Path(path_img_file).stem\n",
    "\n",
    "        for row_idx in range(0, self.num_rows):\n",
    "            for col_idx in range(0, self.num_cols):\n",
    "                h_grid_start = row_idx * self.row_stride\n",
    "                w_grid_start = col_idx * self.col_stride\n",
    "                \n",
    "                patch_xmin = w_grid_start\n",
    "                patch_xmax = w_grid_start+self.window_sz\n",
    "                patch_ymin = h_grid_start\n",
    "                patch_ymax = h_grid_start+self.window_sz\n",
    "                \n",
    "                patch = padded_img[patch_ymin:patch_ymax, patch_xmin:patch_xmax, :] # slice \n",
    "                # print(\"patch sz\", patch.shape)\n",
    "                \n",
    "                patch_name = \"{}_{}_{}\".format(image_filename, row_idx, col_idx)\n",
    "                if path_json_file is not None:\n",
    "                    patch_bboxs = self.get_patch_annotations(patch_xmin, patch_xmax, patch_ymin, patch_ymax, annotations)\n",
    "                    # for patch_bbox in patch_bboxs:\n",
    "                    #     patch = cv2.rectangle(patch, (patch_bbox[0], patch_bbox[1]), (patch_bbox[2], patch_bbox[3]), (255, 255, 0), 1)\n",
    "                    write_json(path_file=\"{}/{}.json\".format(path_patch_dir, patch_name), data=patch_bboxs)\n",
    "                cv2.imwrite(\"{}/{}.jpg\".format(path_patch_dir, patch_name), patch)\n",
    "    \n",
    "    def generate_img_from_patches(self, path_patch_dir, img_name, path_annotation_dir=None):\n",
    "        padded_img = np.zeros(shape=(self.padded_img_height, self.padded_img_width, self.channels), dtype=self.dtype)\n",
    "        img_bboxs = []\n",
    "        for row_idx in range(0, self.num_rows):\n",
    "            for col_idx in range(0, self.num_cols):\n",
    "                h_grid_start = row_idx * self.row_stride\n",
    "                w_grid_start = col_idx * self.col_stride\n",
    "                \n",
    "                patch_xmin = w_grid_start\n",
    "                patch_xmax = w_grid_start+self.window_sz\n",
    "                patch_ymin = h_grid_start\n",
    "                patch_ymax = h_grid_start+self.window_sz\n",
    "                \n",
    "                patch_name = \"{}_{}_{}\".format(img_name, row_idx, col_idx)\n",
    "                patch = cv2.imread(\"{}/{}.jpg\".format(path_patch_dir, patch_name))\n",
    "                \n",
    "                padded_img[patch_ymin:patch_ymax, patch_xmin:patch_xmax, :] = patch\n",
    "                if path_annotation_dir is not None:\n",
    "                    patch_bboxs = read_json(\"{}/{}.json\".format(path_annotation_dir, patch_name))\n",
    "                    for bbox in patch_bboxs:\n",
    "                        xmin, ymin, xmax, ymax = bbox\n",
    "                        xmin = max(xmin + patch_xmin - self.left_pad, 0)\n",
    "                        ymin = max(ymin + patch_ymin - self.top_pad, 0)\n",
    "                        xmax = min(xmax + patch_xmin - self.left_pad, self.width)\n",
    "                        ymax = min(ymax + patch_ymin - self.top_pad, self.height)\n",
    "                        img_bboxs.append([xmin, ymin, xmax, ymax])\n",
    "        \n",
    "        cv2.imwrite(\"padded_img_from_patches.png\", padded_img)\n",
    "        original_img = padded_img[self.left_pad:self.left_pad+self.height, self.right_pad:self.right_pad+self.width, :]\n",
    "        cv2.imwrite(\"original_img_from_patches.png\", np.copy(original_img))\n",
    "        if path_annotation_dir is not None:\n",
    "            mask = np.zeros_like(original_img)\n",
    "            for bbox in img_bboxs:\n",
    "                original_img = cv2.rectangle(original_img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 255), 1)\n",
    "                mask = cv2.rectangle(mask, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 255, 255), -1)\n",
    "            write_json(\"./original_img_bboxes.json\", img_bboxs)\n",
    "            cv2.imwrite(\"original_img_from_patches_with_bboxs.png\", original_img)\n",
    "            cv2.imwrite(\"mask from patches.png\", mask)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_patcher = ImagePatcher(patch_sz=224, overlap=25)\n",
    "image_patcher.generate_patches(path_img_file=\"./DJI_0367.JPG\", path_json_file=\"DJI_0367.json\")\n",
    "image_patcher.generate_img_from_patches(path_patch_dir=\"dataset/patches/\", img_name=\"DJI_0367\", path_annotation_dir=\"dataset/patches/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert bbox from small image to large image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_diagonal_points(bbox):\n",
    "    x, y, width, height = bbox # bbox in  [top left x position, top left y position, width, height]\n",
    "    xmin = x\n",
    "    ymin = y\n",
    "    xmax = x + width \n",
    "    ymax = y + height\n",
    "    start_point = (xmin, ymin)\n",
    "    end_point = (xmax, ymax)\n",
    "    return start_point, end_point\n",
    "\n",
    "def convert(im_w, im_h, x_min, x_max, y_min, y_max):\n",
    "    # yolo format\n",
    "    # https://mrtpk.github.io/deep-learning/2019/09/30/YOLO-annotation.html\n",
    "    dw = 1./im_w\n",
    "    dh = 1./im_h\n",
    "    x = (x_min + x_max)/2.0\n",
    "    y = (y_min + y_max)/2.0\n",
    "    w = x_max - x_min\n",
    "    h = y_max - y_min\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)\n",
    "\n",
    "def deconvert(im_w, im_h, x, y, w, h):\n",
    "    ox = float(x)\n",
    "    oy = float(y)\n",
    "    ow = float(w)\n",
    "    oh = float(h)\n",
    "    x = ox*im_w\n",
    "    y = oy*im_h\n",
    "    w = ow*im_w\n",
    "    h = oh*im_h\n",
    "    xmax = (((2*x)+w)/2)\n",
    "    xmin = xmax-w\n",
    "    ymax = (((2*y)+h)/2)\n",
    "    ymin = ymax-h\n",
    "    return [int(xmin),int(ymin),int(xmax),int(ymax)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'id': 0,\n",
       "   'license': 1,\n",
       "   'file_name': 'DJI_0367_JPG.rf.d83afb6717d6b0fd215e19e8eec1267b.jpg',\n",
       "   'height': 1536,\n",
       "   'width': 2048,\n",
       "   'date_captured': '2021-06-02T17:58:51+00:00'}],\n",
       " (1536, 2048, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_annotated_img = \"./sample_dataset_with_annotations/DJI_0367_JPG.rf.d83afb6717d6b0fd215e19e8eec1267b.jpg\"\n",
    "path_annotated_json = \"./sample_dataset_with_annotations/_annotations.coco.json\"\n",
    "annotaed_img = cv2.imread(path_annotated_img)\n",
    "annotations = read_json(path_annotated_json)\n",
    "annotations['images'], annotaed_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations['images'], annotations['annotations']\n",
    "# This code converts bbox in small image to bbox in large image\n",
    "annotaed_img_viz = np.copy(annotaed_img).astype(np.uint8)\n",
    "big_img = cv2.imread(\"DJI_0367.JPG\")\n",
    "bboxes_big = []\n",
    "for annotation in annotations['annotations']:\n",
    "    bbox = annotation['bbox'] #  [x,y,width,height]\n",
    "    \n",
    "    start_point, end_point = convert_to_diagonal_points(bbox=bbox)\n",
    "    x,y,w,h = convert(im_w=2048, im_h=1536, x_min=start_point[0], x_max=end_point[0], y_min=start_point[1], y_max=end_point[1])\n",
    "    xmin_big, ymin_big, xmax_big, ymax_big = deconvert(im_w=big_img.shape[1], im_h=big_img.shape[0], x=x, y=y, w=w, h=h)\n",
    "    \n",
    "    bboxes_big.append([xmin_big, ymin_big, xmax_big, ymax_big])\n",
    "    annotaed_img_viz = cv2.rectangle(annotaed_img_viz, start_point, end_point, (0, 255, 0), 1)\n",
    "    big_img = cv2.rectangle(big_img, (xmin_big, ymin_big), (xmax_big, ymax_big), (0, 255, 0), 1)\n",
    "cv2.imwrite(\"annoated_img_viz.png\", annotaed_img_viz)\n",
    "cv2.imwrite(\"annoated_big_img_viz.png\", big_img)\n",
    "write_json(\"./DJI_0367.json\", bboxes_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
